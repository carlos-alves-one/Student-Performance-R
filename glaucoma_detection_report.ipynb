{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNzTVqKG9qz1kVljGdyeSCT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-SSDM-Coursework-1/blob/main/glaucoma_detection_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goldsmiths University of London\n",
        "### MSc. Data Science and Artificial Intelligence\n",
        "### Module: Artificial Intelligence\n",
        "### Author: Carlos Manuel De Oliveira Alves\n",
        "### Student: cdeol003\n",
        "### Coursework No.2"
      ],
      "metadata": {
        "id": "xzMEUBjqyD2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project\n",
        "VisionGuard AI: Deep Learning for Early Glaucoma Detection"
      ],
      "metadata": {
        "id": "3m_s3jj2ykLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "dKmrlfDHyrBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this research is to outline the progression of a deep-learning model designed to identify glaucoma through the analysis of ocular pictures. Glaucoma is a debilitating ocular disorder that, if left undetected and untreated in its early stages, can result in complete vision loss. Effective screening procedures are necessary due to the asymptomatic nature of the early stages of glaucoma. Deep learning, specifically convolutional neural networks (CNNs), has demonstrated considerable potential in image identification tasks and can aid in the early detection of glaucoma. The dataset utilised in this research comprises a collection of ocular pictures accompanied by a binary classification showing the presence or absence of glaucoma. The ExpCDR, or 'Cup to Disc Ratio', is a crucial clinical parameter utilised in evaluating glaucoma for each image."
      ],
      "metadata": {
        "id": "J2ATgtijyt6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "Z_0kKAKPzUBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "KrJPhnITCbvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The photos will undergo a process of loading, resizing to a consistent dimension, and normalisation to ensure that their pixel values fall within the range of 0 to 1. Furthermore, it is possible to employ data augmentation methods, such as rotations, shifts, and flips, in order to augment the size and diversity of the dataset. This can be beneficial in mitigating the issue of overfitting."
      ],
      "metadata": {
        "id": "GolCWF_9Cc05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "vJxQknsHCnRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the 'drive' module from 'google.colab' and mounts the Google Drive to\n",
        "# the '/content/drive' directory in the Colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8qRwA8fCpGx",
        "outputId": "992ec109-a357-4d73-c18e-4b92ff9a8b06"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library and give it the alias 'pd' for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset glaucoma from Google Drive\n",
        "data_path = '/content/drive/MyDrive/glaucoma.csv'\n",
        "glaucoma_data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "glaucoma_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yITsqdLEC_td",
        "outputId": "a71adb08-66c8-4cf7-89a1-cdb12ce8cfb1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Filename  ExpCDR Eye Set  Glaucoma\n",
              "0  001.jpg  0.7097  OD   A         0\n",
              "1  002.jpg  0.6953  OS   A         0\n",
              "2  003.jpg  0.9629  OS   A         0\n",
              "3  004.jpg  0.7246  OD   A         0\n",
              "4  005.jpg  0.6138  OS   A         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9f13a988-964b-4b45-83b1-22ec0363cbcd\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>ExpCDR</th>\n",
              "      <th>Eye</th>\n",
              "      <th>Set</th>\n",
              "      <th>Glaucoma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.jpg</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.jpg</td>\n",
              "      <td>0.6953</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.jpg</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.jpg</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.jpg</td>\n",
              "      <td>0.6138</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9f13a988-964b-4b45-83b1-22ec0363cbcd')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-9f13a988-964b-4b45-83b1-22ec0363cbcd button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-9f13a988-964b-4b45-83b1-22ec0363cbcd');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-066bc1b7-2d1d-43ed-8f06-9ee9d3b598cc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-066bc1b7-2d1d-43ed-8f06-9ee9d3b598cc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-066bc1b7-2d1d-43ed-8f06-9ee9d3b598cc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset source: https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection"
      ],
      "metadata": {
        "id": "fZNyLGQ_DPGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "License: CC0 - Public Domain\n",
        "https://creativecommons.org/publicdomain/zero/1.0/"
      ],
      "metadata": {
        "id": "3M4yTljuDRJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains the following columns:\n",
        "\n",
        "    - Filename: The name of the image file.\n",
        "    - ExpCDR: The 'Cup to Disc Ratio', a crucial parameter for evaluating glaucoma.\n",
        "    - Eye: Indicates which eye the image corresponds to (OD for right eye, OS for left eye).\n",
        "    - Set: This could denote the dataset split (e.g., training, validation, or test set), but we would need further clarification.\n",
        "    - Glaucoma: The binary label indicating the presence (1) or absence (0) of glaucoma."
      ],
      "metadata": {
        "id": "xMxYuhP8Dzz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess the Data"
      ],
      "metadata": {
        "id": "a1p9dD7TAZkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare function to preprocess a single image:\n",
        "\n",
        "The following code snippet presents a Python script that use TensorFlow for the purpose of picture preparation. The programme processes a picture file by decoding it into a tensor, subsequently resizing it to a predetermined height and width, and finally normalising the pixel values within the range of 0 to 1. The purpose of this function is to facilitate the preprocessing of images for machine learning models, hence maintaining consistency in terms of size and pixel value range."
      ],
      "metadata": {
        "id": "LS9WwTdJAesI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the os module for interacting with the operating system and tensorflow for machine learning tasks\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(filename, img_height=224, img_width=224, images_directory='/content/drive/MyDrive/Images'):\n",
        "\n",
        "    # Join the directory path and filename to form the full path to an image\n",
        "    image_path = os.path.join(images_directory, filename)\n",
        "\n",
        "    # Read the image file from the specified path into a tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "\n",
        "    # Decode the JPEG image and ensure it has 3 color channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize the image to the specified height and width using TensorFlow's resize function\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "\n",
        "    # Normalize the image pixels to the range 0-1 for model compatibility\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Return image preprocessed\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "w1RNnhFaAmiH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "aav0Y_8yBIF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Set up data augmentation using the ImageDataGenerator class from tf.keras.preprocessing.image:\n",
        "\n",
        " The code that follows the snippet demonstrates the utilisation of TensorFlow's Keras API to initialise an image data augmentation pipeline. More specifically, it employs the ImageDataGenerator class. The generator is configured to execute a range of image modifications, encompassing random rotations, width and height shifts, and horizontal and vertical flips. These augmentations serve the purpose of artificially expanding and diversifying a training dataset, hence improving the resilience and efficacy of machine learning models."
      ],
      "metadata": {
        "id": "5Thx6cecBJ59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ImageDataGenerator class from TensorFlow's Keras API for real-time data augmentation of images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "\n",
        "    # Configures the image augmentation by rotating images within 20 degrees randomly\n",
        "    rotation_range=20,\n",
        "\n",
        "    # Specifies that the input width can be shifted by a maximum of 20% either left or right\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    # Randomly shift the height of images during training by a factor of 20%\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    # Enables horizontal and vertical flipping of images\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "DeJNp54GBZfR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply Preprocessing and Augmentation to Dataset"
      ],
      "metadata": {
        "id": "Ogafn90aB3d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following code snippet is responsible for extracting filenames and their matching glaucoma presence labels from a dataset. Additionally, it establishes a directory path for the picture files. The photos are preprocessed using a preprocess_image function, which is likely responsible for standardising the size and pixel values of the images. Ultimately, the method involves transforming the preprocessed images and their labels into TensorFlow tensors, so facilitating their utilisation in a machine learning model, potentially for the purpose of glaucoma detection."
      ],
      "metadata": {
        "id": "H6fgXC6rB5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract filenames and corresponding glaucoma presence labels from the dataset\n",
        "filenames = glaucoma_data['Filename'].values\n",
        "labels = glaucoma_data['Glaucoma'].values\n",
        "\n",
        "# A placeholder for the images directory\n",
        "images_directory = '/content/drive/MyDrive/Images'\n",
        "\n",
        "# Preprocess all images\n",
        "images = [preprocess_image(f, images_directory=images_directory) for f in filenames]\n",
        "\n",
        "# Convert to Tensor\n",
        "images = tf.stack(images)\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "VHGyoTKtCNFk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split the data\n",
        "The dataset will be split into training, validation, and test sets. The model will be compiled with an appropriate loss function and optimizer, and trained for a specified number of epochs while monitoring the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "TL6xQLR2EgG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function from scikit-learn to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import TensorFlow for deep learning and train_test_split function for splitting the dataset into training and testing sets\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert image and label tensors to numpy arrays for further manipulation or analysis\n",
        "images_numpy = images.numpy()\n",
        "labels_numpy = labels.numpy()\n",
        "\n",
        "# Split the dataset into training set and a combined validation/test set with a 20% size of the original dataset,\n",
        "# using a fixed random state for reproducibility.\n",
        "train_images, val_test_images, train_labels, val_test_labels = train_test_split(\n",
        "    images_numpy, labels_numpy, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Split the val_test set equally into validation and test sets (50% validation, 50% test)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    val_test_images, val_test_labels, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "Hpd2KKLLEiGg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "The model will be a CNN, known for its performance in image classification tasks. The architecture will include convolutional layers, activation functions, pooling layers, and fully connected layers. Dropout layers may be included to reduce overfitting."
      ],
      "metadata": {
        "id": "ODQzViI7FQBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet sets up the label data for a neural network-based classification model, ensuring that the labels are in a format that can be effectively used for training and evaluation within a TensorFlow framework. This preprocessing step is critical to the machine learning pipeline for classification problems."
      ],
      "metadata": {
        "id": "gyx_QZ9DC_Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the NumPy library for numerical operations.\n",
        "import numpy as np\n",
        "\n",
        "# Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Convert train labels to one-hot encoded format\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "\n",
        "# Convert validation labels to one-hot encoded format\n",
        "val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "# Convert test labels to one-hot encoded format\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "CdV8GfXmHtiz"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates the construction, training, and evaluation of a Convolutional Neural Network (CNN) for image classification using TensorFlow. It includes defining the model architecture with convolutional, pooling, and dense layers, followed by compilation with appropriate loss and optimization functions. The model is then trained on labeled image data, evaluated for accuracy on a test set, and the test accuracy is reported, showcasing the end-to-end process of a typical deep learning image classification task.\n"
      ],
      "metadata": {
        "id": "jBsCq-rNt8Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer with shape 224x224 and 3 color channels (RGB)\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "# Apply a 2D convolution layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "\n",
        "# Add a max pooling layer with a 2x2 pool size to reduce spatial dimensions\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "# Add another convolution layer with 64 filters, 3x3 kernel, and ReLU activation\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "# Add a second max pooling layer to further reduce dimensions.\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "# Add a third convolution layer with 128 filters, 3x3 kernel, and ReLU activation\n",
        "x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "# Flatten the output to prepare for the dense layer\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# Determine the number of classes from the shape of the training labels\n",
        "num_classes = train_labels.shape[1]\n",
        "\n",
        "# Create the output layer with 'num_classes' neurons and softmax activation\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "# Build the model by specifying inputs and outputs\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Print the accuracy results for this model\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzxif_lwyxiI",
        "outputId": "739f3613-f0e4-476b-b43b-dc4279624932"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 13s 107ms/step - loss: 0.9423 - accuracy: 0.6389 - val_loss: 0.5324 - val_accuracy: 0.8269\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 1s 52ms/step - loss: 0.5819 - accuracy: 0.7329 - val_loss: 0.4994 - val_accuracy: 0.8269\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 1s 52ms/step - loss: 0.5862 - accuracy: 0.7329 - val_loss: 0.4713 - val_accuracy: 0.8269\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 1s 54ms/step - loss: 0.5737 - accuracy: 0.7329 - val_loss: 0.5324 - val_accuracy: 0.8269\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 1s 57ms/step - loss: 0.5670 - accuracy: 0.7350 - val_loss: 0.4842 - val_accuracy: 0.8269\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 1s 57ms/step - loss: 0.5533 - accuracy: 0.7457 - val_loss: 0.4864 - val_accuracy: 0.8846\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 1s 58ms/step - loss: 0.5406 - accuracy: 0.7436 - val_loss: 0.4676 - val_accuracy: 0.8846\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 1s 57ms/step - loss: 0.5212 - accuracy: 0.7457 - val_loss: 0.4266 - val_accuracy: 0.8269\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 1s 56ms/step - loss: 0.5195 - accuracy: 0.7735 - val_loss: 0.4809 - val_accuracy: 0.8462\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 1s 60ms/step - loss: 0.4915 - accuracy: 0.7628 - val_loss: 0.4013 - val_accuracy: 0.8654\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.5269 - accuracy: 0.7538\n",
            "Test accuracy: 0.7538\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analysis of the Initial Model"
      ],
      "metadata": {
        "id": "YB0QUOLLSHxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is a relatively simple Convolutional Neural Network (CNN) model designed for image classification tasks. It has been built using TensorFlow and Keras, and the architecture is straightforward, making it suitable for small to medium-sized datasets and a starting point for more complex tasks. Here is a breakdown of the model:\n",
        "\n",
        "1. Input Layer: Accepts images of size 224x224 with three colour channels (RGB).\n",
        "2. Convolutional Layers:\n",
        "   - The first convolutional layer has 32 filters of size 3x3 with ReLU activation.\n",
        "   - The second convolutional layer has 64 filters of size 3x3 with ReLU activation.\n",
        "   - The third convolutional layer has 128 filters of size 3x3 with ReLU activation.\n",
        "3. Pooling Layers: Two max-pooling layers are used to reduce the spatial dimensions of the feature maps.\n",
        "4. Flatten Layer: Flattens the output for the dense layer.\n",
        "5. Output Layer: A dense layer with some neurons equal to the number of classes (`num_classes`), using softmax activation for multi-class classification.\n",
        "\n",
        "The model is compiled with the Adam optimizer, categorical cross-entropy loss, and accuracy metric. It has trained for ten epochs with a validation split of 0.1.\n",
        "\n",
        "This model is suitable for learning or initial experimentation with image classification tasks."
      ],
      "metadata": {
        "id": "he-yxuH8SaeZ"
      }
    }
  ]
}