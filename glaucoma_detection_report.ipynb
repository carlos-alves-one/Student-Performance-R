{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPUtB2CKpmW0fKlkMn73Gaz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/carlos-alves-one/-SSDM-Coursework-1/blob/main/glaucoma_detection_report.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Goldsmiths University of London\n",
        "### MSc. Data Science and Artificial Intelligence\n",
        "### Module: Artificial Intelligence\n",
        "### Author: Carlos Manuel De Oliveira Alves\n",
        "### Student: cdeol003\n",
        "### Coursework No.2"
      ],
      "metadata": {
        "id": "xzMEUBjqyD2s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Project\n",
        "VisionGuard AI: Deep Learning for Early Glaucoma Detection"
      ],
      "metadata": {
        "id": "3m_s3jj2ykLt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "dKmrlfDHyrBK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The purpose of this research is to outline the progression of a deep-learning model designed to identify glaucoma through the analysis of ocular pictures. Glaucoma is a debilitating ocular disorder that, if left undetected and untreated in its early stages, can result in complete vision loss. Effective screening procedures are necessary due to the asymptomatic nature of the early stages of glaucoma. Deep learning, specifically convolutional neural networks (CNNs), has demonstrated considerable potential in image identification tasks and can aid in the early detection of glaucoma. The dataset utilised in this research comprises a collection of ocular pictures accompanied by a binary classification showing the presence or absence of glaucoma. The ExpCDR, or 'Cup to Disc Ratio', is a crucial clinical parameter utilised in evaluating glaucoma for each image."
      ],
      "metadata": {
        "id": "J2ATgtijyt6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology"
      ],
      "metadata": {
        "id": "Z_0kKAKPzUBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ],
      "metadata": {
        "id": "KrJPhnITCbvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The photos will undergo a process of loading, resizing to a consistent dimension, and normalisation to ensure that their pixel values fall within the range of 0 to 1. Furthermore, it is possible to employ data augmentation methods, such as rotations, shifts, and flips, in order to augment the size and diversity of the dataset. This can be beneficial in mitigating the issue of overfitting."
      ],
      "metadata": {
        "id": "GolCWF_9Cc05"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load the data"
      ],
      "metadata": {
        "id": "vJxQknsHCnRD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Imports the 'drive' module from 'google.colab' and mounts the Google Drive to\n",
        "# the '/content/drive' directory in the Colab environment.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J8qRwA8fCpGx",
        "outputId": "91efc8f2-975b-4225-f593-c6ea28fe9425"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the pandas library and give it the alias 'pd' for data manipulation and analysis\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset glaucoma from Google Drive\n",
        "data_path = '/content/drive/MyDrive/glaucoma.csv'\n",
        "glaucoma_data = pd.read_csv(data_path)\n",
        "\n",
        "# Display the first few rows of the dataframe\n",
        "glaucoma_data.head()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yITsqdLEC_td",
        "outputId": "1fc90c68-db89-4653-ad7b-ffda7a74223b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  Filename  ExpCDR Eye Set  Glaucoma\n",
              "0  001.jpg  0.7097  OD   A         0\n",
              "1  002.jpg  0.6953  OS   A         0\n",
              "2  003.jpg  0.9629  OS   A         0\n",
              "3  004.jpg  0.7246  OD   A         0\n",
              "4  005.jpg  0.6138  OS   A         0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f9b566af-01ac-4509-98ea-2e17cafc70c1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>ExpCDR</th>\n",
              "      <th>Eye</th>\n",
              "      <th>Set</th>\n",
              "      <th>Glaucoma</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>001.jpg</td>\n",
              "      <td>0.7097</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>002.jpg</td>\n",
              "      <td>0.6953</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>003.jpg</td>\n",
              "      <td>0.9629</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>004.jpg</td>\n",
              "      <td>0.7246</td>\n",
              "      <td>OD</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>005.jpg</td>\n",
              "      <td>0.6138</td>\n",
              "      <td>OS</td>\n",
              "      <td>A</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9b566af-01ac-4509-98ea-2e17cafc70c1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f9b566af-01ac-4509-98ea-2e17cafc70c1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f9b566af-01ac-4509-98ea-2e17cafc70c1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-75f77883-d5d1-47d8-8ce3-baa7fba2a724\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-75f77883-d5d1-47d8-8ce3-baa7fba2a724')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-75f77883-d5d1-47d8-8ce3-baa7fba2a724 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset source: https://www.kaggle.com/datasets/sshikamaru/glaucoma-detection"
      ],
      "metadata": {
        "id": "fZNyLGQ_DPGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "License: CC0 - Public Domain\n",
        "https://creativecommons.org/publicdomain/zero/1.0/"
      ],
      "metadata": {
        "id": "3M4yTljuDRJd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains the following columns:\n",
        "\n",
        "    - Filename: The name of the image file.\n",
        "    - ExpCDR: The 'Cup to Disc Ratio', a crucial parameter for evaluating glaucoma.\n",
        "    - Eye: Indicates which eye the image corresponds to (OD for right eye, OS for left eye).\n",
        "    - Set: This could denote the dataset split (e.g., training, validation, or test set), but we would need further clarification.\n",
        "    - Glaucoma: The binary label indicating the presence (1) or absence (0) of glaucoma."
      ],
      "metadata": {
        "id": "xMxYuhP8Dzz5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Preprocess the Data"
      ],
      "metadata": {
        "id": "a1p9dD7TAZkC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Declare function to preprocess a single image:\n",
        "\n",
        "The following code snippet presents a Python script that use TensorFlow for the purpose of picture preparation. The programme processes a picture file by decoding it into a tensor, subsequently resizing it to a predetermined height and width, and finally normalising the pixel values within the range of 0 to 1. The purpose of this function is to facilitate the preprocessing of images for machine learning models, hence maintaining consistency in terms of size and pixel value range."
      ],
      "metadata": {
        "id": "LS9WwTdJAesI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the os module for interacting with the operating system and tensorflow for machine learning tasks\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "# Function to preprocess a single image\n",
        "def preprocess_image(filename, img_height=224, img_width=224, images_directory='/content/drive/MyDrive/Images'):\n",
        "\n",
        "    # Join the directory path and filename to form the full path to an image\n",
        "    image_path = os.path.join(images_directory, filename)\n",
        "\n",
        "    # Read the image file from the specified path into a tensor\n",
        "    image = tf.io.read_file(image_path)\n",
        "\n",
        "    # Decode the JPEG image and ensure it has 3 color channels (RGB)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "\n",
        "    # Resize the image to the specified height and width using TensorFlow's resize function\n",
        "    image = tf.image.resize(image, [img_height, img_width])\n",
        "\n",
        "    # Normalize the image pixels to the range 0-1 for model compatibility\n",
        "    image = image / 255.0\n",
        "\n",
        "    # Return image preprocessed\n",
        "    return image\n"
      ],
      "metadata": {
        "id": "w1RNnhFaAmiH"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Data Augmentation"
      ],
      "metadata": {
        "id": "aav0Y_8yBIF1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Set up data augmentation using the ImageDataGenerator class from tf.keras.preprocessing.image:\n",
        "\n",
        " The code that follows the snippet demonstrates the utilisation of TensorFlow's Keras API to initialise an image data augmentation pipeline. More specifically, it employs the ImageDataGenerator class. The generator is configured to execute a range of image modifications, encompassing random rotations, width and height shifts, and horizontal and vertical flips. These augmentations serve the purpose of artificially expanding and diversifying a training dataset, hence improving the resilience and efficacy of machine learning models."
      ],
      "metadata": {
        "id": "5Thx6cecBJ59"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the ImageDataGenerator class from TensorFlow's Keras API for real-time data augmentation of images\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Set up data augmentation\n",
        "data_augmentation = ImageDataGenerator(\n",
        "\n",
        "    # Configures the image augmentation by rotating images within 20 degrees randomly\n",
        "    rotation_range=20,\n",
        "\n",
        "    # Specifies that the input width can be shifted by a maximum of 20% either left or right\n",
        "    width_shift_range=0.2,\n",
        "\n",
        "    # Randomly shift the height of images during training by a factor of 20%\n",
        "    height_shift_range=0.2,\n",
        "\n",
        "    # Enables horizontal and vertical flipping of images\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "DeJNp54GBZfR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Apply Preprocessing and Augmentation to Dataset"
      ],
      "metadata": {
        "id": "Ogafn90aB3d2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code extracts image filenames and corresponding labels for glaucoma detection from the dataset, preprocesses the images, and then applies data augmentation techniques like rotation and flipping. The augmented images are converted into a Numpy array and then to TensorFlow tensors, ensuring compatibility with TensorFlow-based models. The process is critical for preparing a dataset of images and labels for training or evaluating a machine-learning model, specifically for tasks like glaucoma detection."
      ],
      "metadata": {
        "id": "H6fgXC6rB5UE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the NumPy library for numerical operations.\n",
        "import numpy as np\n",
        "\n",
        "# Extract filenames and corresponding glaucoma presence labels from the dataset\n",
        "filenames = glaucoma_data['Filename'].values\n",
        "labels = glaucoma_data['Glaucoma'].values\n",
        "\n",
        "# A placeholder for the images directory\n",
        "images_directory = '/content/drive/MyDrive/Images'\n",
        "\n",
        "# Preprocess all images\n",
        "preprocessed_images = [preprocess_image(f, images_directory=images_directory) for f in filenames]\n",
        "\n",
        "# Convert the list of images to a Numpy array\n",
        "images_np = np.array(preprocessed_images)\n",
        "\n",
        "# Create a generator for augmentation\n",
        "augmented_images_generator = data_augmentation.flow(images_np, batch_size=1, shuffle=False)\n",
        "\n",
        "# Collect augmented images\n",
        "augmented_images = []\n",
        "for i in range(len(preprocessed_images)):\n",
        "    # Get the next augmented image from the generator\n",
        "    augmented_image = next(augmented_images_generator)[0]\n",
        "\n",
        "    # Remove batch dimension and append to list\n",
        "    augmented_images.append(augmented_image)\n",
        "\n",
        "# Convert the list of augmented images to a Tensor\n",
        "images = tf.stack(augmented_images)\n",
        "\n",
        "# Convert labels to Tensor\n",
        "labels = tf.convert_to_tensor(labels)\n"
      ],
      "metadata": {
        "id": "VHGyoTKtCNFk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Split the data\n",
        "The dataset will be split into training, validation, and test sets. The model will be compiled with an appropriate loss function and optimizer, and trained for a specified number of epochs while monitoring the loss and accuracy on the validation set."
      ],
      "metadata": {
        "id": "TL6xQLR2EgG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import train_test_split function from scikit-learn to split data into training and test sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Import TensorFlow for deep learning and train_test_split function for splitting the dataset into training and testing sets\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Convert image and label tensors to numpy arrays for further manipulation or analysis\n",
        "images_numpy = images.numpy()\n",
        "labels_numpy = labels.numpy()\n",
        "\n",
        "# Split the dataset into training set and a combined validation/test set with a 20% size of the original dataset,\n",
        "# using a fixed random state for reproducibility.\n",
        "train_images, val_test_images, train_labels, val_test_labels = train_test_split(\n",
        "    images_numpy, labels_numpy, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Split the val_test set equally into validation and test sets (50% validation, 50% test)\n",
        "val_images, test_images, val_labels, test_labels = train_test_split(\n",
        "    val_test_images, val_test_labels, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "id": "Hpd2KKLLEiGg"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Architecture\n",
        "The model will be a CNN, known for its performance in image classification tasks. The architecture will include convolutional layers, activation functions, pooling layers, and fully connected layers. Dropout layers may be included to reduce overfitting."
      ],
      "metadata": {
        "id": "ODQzViI7FQBy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The code snippet sets up the label data for a neural network-based classification model, ensuring that the labels are in a format that can be effectively used for training and evaluation within a TensorFlow framework. This preprocessing step is critical to the machine learning pipeline for classification problems."
      ],
      "metadata": {
        "id": "gyx_QZ9DC_Lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " # Determine the number of unique classes in the training labels\n",
        "num_classes = len(np.unique(train_labels))\n",
        "\n",
        "# Convert train labels to one-hot encoded format\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes=num_classes)\n",
        "\n",
        "# Convert validation labels to one-hot encoded format\n",
        "val_labels = tf.keras.utils.to_categorical(val_labels, num_classes=num_classes)\n",
        "\n",
        "# Convert test labels to one-hot encoded format\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes=num_classes)\n"
      ],
      "metadata": {
        "id": "CdV8GfXmHtiz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code demonstrates the construction, training, and evaluation of a Convolutional Neural Network (CNN) for image classification using TensorFlow. It includes defining the model architecture with convolutional, pooling, and dense layers, followed by compilation with appropriate loss and optimization functions. The model is then trained on labeled image data, evaluated for accuracy on a test set, and the test accuracy is reported, showcasing the end-to-end process of a typical deep learning image classification task.\n"
      ],
      "metadata": {
        "id": "jBsCq-rNt8Ql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the input layer with shape 224x224 and 3 color channels (RGB)\n",
        "inputs = tf.keras.Input(shape=(224, 224, 3))\n",
        "\n",
        "# Apply a 2D convolution layer with 32 filters, 3x3 kernel, and ReLU activation\n",
        "x = tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n",
        "\n",
        "# Add a max pooling layer with a 2x2 pool size to reduce spatial dimensions\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "# Add another convolution layer with 64 filters, 3x3 kernel, and ReLU activation\n",
        "x = tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "# Add a second max pooling layer to further reduce dimensions.\n",
        "x = tf.keras.layers.MaxPooling2D(pool_size=2)(x)\n",
        "\n",
        "# Add a third convolution layer with 128 filters, 3x3 kernel, and ReLU activation\n",
        "x = tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\")(x)\n",
        "\n",
        "# Flatten the output to prepare for the dense layer\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "\n",
        "# Determine the number of classes from the shape of the training labels\n",
        "num_classes = train_labels.shape[1]\n",
        "\n",
        "# Create the output layer with 'num_classes' neurons and softmax activation\n",
        "outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "# Build the model by specifying inputs and outputs\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(train_images, train_labels, epochs=10, validation_split=0.1)\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_accuracy = model.evaluate(test_images, test_labels)\n",
        "\n",
        "# Print the accuracy results for this model\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yzxif_lwyxiI",
        "outputId": "afc2ece1-ed01-4f17-fd70-1941c6a7f6e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "15/15 [==============================] - 12s 106ms/step - loss: 0.9009 - accuracy: 0.6581 - val_loss: 0.5735 - val_accuracy: 0.8269\n",
            "Epoch 2/10\n",
            "15/15 [==============================] - 1s 54ms/step - loss: 0.5924 - accuracy: 0.7329 - val_loss: 0.5939 - val_accuracy: 0.8269\n",
            "Epoch 3/10\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.5907 - accuracy: 0.7329 - val_loss: 0.5834 - val_accuracy: 0.8269\n",
            "Epoch 4/10\n",
            "15/15 [==============================] - 1s 57ms/step - loss: 0.5637 - accuracy: 0.7457 - val_loss: 0.5574 - val_accuracy: 0.8269\n",
            "Epoch 5/10\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.4786 - accuracy: 0.7564 - val_loss: 0.5644 - val_accuracy: 0.7500\n",
            "Epoch 6/10\n",
            "15/15 [==============================] - 1s 57ms/step - loss: 0.3569 - accuracy: 0.8397 - val_loss: 0.8334 - val_accuracy: 0.6346\n",
            "Epoch 7/10\n",
            "15/15 [==============================] - 1s 59ms/step - loss: 0.2384 - accuracy: 0.9167 - val_loss: 0.7014 - val_accuracy: 0.7308\n",
            "Epoch 8/10\n",
            "15/15 [==============================] - 1s 55ms/step - loss: 0.1490 - accuracy: 0.9402 - val_loss: 0.7438 - val_accuracy: 0.7308\n",
            "Epoch 9/10\n",
            "15/15 [==============================] - 1s 57ms/step - loss: 0.1078 - accuracy: 0.9722 - val_loss: 1.2559 - val_accuracy: 0.7692\n",
            "Epoch 10/10\n",
            "15/15 [==============================] - 1s 49ms/step - loss: 0.0872 - accuracy: 0.9722 - val_loss: 1.0835 - val_accuracy: 0.7308\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 2.1843 - accuracy: 0.6308\n",
            "Test accuracy: 0.6308\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Analysis of the Initial Model"
      ],
      "metadata": {
        "id": "YB0QUOLLSHxo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This model is a relatively simple Convolutional Neural Network (CNN) model designed for image classification tasks. It has been built using TensorFlow and Keras, and the architecture is straightforward, making it suitable for small to medium-sized datasets and a starting point for more complex tasks. Here is a breakdown of the model:\n",
        "\n",
        "1. Input Layer: Accepts images of size 224x224 with three colour channels (RGB).\n",
        "2. Convolutional Layers:\n",
        "   - The first convolutional layer has 32 filters of size 3x3 with ReLU activation.\n",
        "   - The second convolutional layer has 64 filters of size 3x3 with ReLU activation.\n",
        "   - The third convolutional layer has 128 filters of size 3x3 with ReLU activation.\n",
        "3. Pooling Layers: Two max-pooling layers are used to reduce the spatial dimensions of the feature maps.\n",
        "4. Flatten Layer: Flattens the output for the dense layer.\n",
        "5. Output Layer: A dense layer with some neurons equal to the number of classes (`num_classes`), using softmax activation for multi-class classification.\n",
        "\n",
        "The model is compiled with the Adam optimizer, categorical cross-entropy loss, and accuracy metric. It has trained for ten epochs with a validation split of 0.1.\n",
        "\n",
        "This model is suitable for learning or initial experimentation with image classification tasks."
      ],
      "metadata": {
        "id": "he-yxuH8SaeZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating the model on the test set"
      ],
      "metadata": {
        "id": "dEnPDzma6Fpj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the matplotlib.pyplot module for plotting graphs and charts\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Import the seaborn module for advanced data visualization\n",
        "import seaborn as sns\n",
        "\n",
        "# Importing classification_report and confusion_matrix functions from the scikit-learn metrics module\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "predicted_classes = model.predict(test_images)\n",
        "\n",
        "# Convert predictions to label indexes\n",
        "predicted_classes = np.argmax(predicted_classes, axis=1)\n",
        "\n",
        "# Convert one-hot encoded test labels back to label indexes\n",
        "true_classes = np.argmax(test_labels, axis=1)\n",
        "\n",
        "# Generate the confusion matrix\n",
        "cm = confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "# Plotting the normalized confusion matrix\n",
        "plt.figure(figsize=(8, 7))\n",
        "sns.heatmap(cm, annot=True, fmt='.2f', vmin=0, cmap='Blues', cbar=True)\n",
        "plt.xlabel('Predicted label')\n",
        "plt.ylabel('True label')\n",
        "plt.title('Normalized confusion matrix')\n",
        "# Update the x and y ticks to match the provided classes\n",
        "plt.xticks(ticks=[0.5, 1.5], labels=['Not Glaucoma', 'Glaucoma'])\n",
        "plt.yticks(ticks=[0.5, 1.5], labels=['Not Glaucoma', 'Glaucoma'])\n",
        "plt.show()\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(true_classes, predicted_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 815
        },
        "id": "Vln-ozE56NKd",
        "outputId": "56decaf0-87c2-4e04-9ef0-1caa813c8964"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 15ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.81      0.76        47\n",
            "           1       0.25      0.17      0.20        18\n",
            "\n",
            "    accuracy                           0.63        65\n",
            "   macro avg       0.48      0.49      0.48        65\n",
            "weighted avg       0.59      0.63      0.60        65\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Analyze Test Results"
      ],
      "metadata": {
        "id": "yVsXLbZx68og"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The table above shows a normalized confusion matrix for a binary classification task, where the classes are \"Not Glaucoma\" and \"Glaucoma\". Here is the analysis:\n",
        "\n",
        "1. Top-left cell (True Negative Rate): The value \"47.00\" suggests that the model correctly predicted 100% of the actual \"Not Glaucoma\" cases as \"Not Glaucoma\". This is the true negative rate.\n",
        "\n",
        "2. Bottom-left cell (False Negative Rate): The value \"17.00\" indicates that the model incorrectly predicted 100% of the actual \"Glaucoma\" cases as \"Not Glaucoma\". This false negative rate is quite concerning in a medical diagnostic context, as it means all cases of Glaucoma were missed.\n",
        "\n",
        "3. Top-right cell (False Positive Rate): The value \"0.00\" means there were no false positives, i.e., no \"Not Glaucoma\" cases were incorrectly identified as \"Glaucoma\".\n",
        "\n",
        "4. Bottom-right cell (True Positive Rate): The value \"1.00\" should represent the proportion of actual \"Glaucoma\" cases correctly identified. However, this is an inconsistency given the false negative rate of 100%, as there cannot be both 100% false negatives and any true positives.\n",
        "\n",
        "Given this confusion, clarifying the values in the confusion matrix is essential. The usual interpretation of a normalized confusion matrix is that all values are between 0 and 1, representing the proportion of the total number of cases. A value of \"1.00\" in a normalized confusion matrix would typically indicate that 100% of the predictions in that category are of that type. Therefore, having \"1.00\" in both the True Negative and False Negative places is contradictory unless there were no \"Glaucoma\" cases, which would mean the dataset might not be balanced or there was an issue with model predictions.\n",
        "Based on the expected behaviour of a confusion matrix, here is what could be the correct interpretation:\n",
        "The model has a very high specificity, which is very good at identifying negative cases (\"Not Glaucoma\").\n",
        "The model has zero sensitivity, meaning it fails to identify positive cases (\"Glaucoma\"), a severe issue for a medical diagnostic tool.\n",
        "This outcome would require immediate attention to understand why the model is not correctly identifying any positive cases. It could be due to class imbalance, inadequate training, or insufficiently distinctive features for the \"Glaucoma\" class."
      ],
      "metadata": {
        "id": "GmhH_Xv69egF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Check Balance of the Dataset"
      ],
      "metadata": {
        "id": "STqi4FCHIQI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the dataset\n",
        "class_distribution = glaucoma_data['Glaucoma'].value_counts()\n",
        "\n",
        "# Print the distribution\n",
        "print(f\"Distribution:\\n{class_distribution}\\n\")\n",
        "\n",
        "# Optionally, calculate the percentage of each class\n",
        "class_percentage = class_distribution / len(glaucoma_data) * 100\n",
        "print(f\"Percentage of each class:\\n{class_percentage}\\n\")\n",
        "\n",
        "# Print the results of the dataset\n",
        "print(f\"Number of instances without Glaucoma (0)..: {class_distribution.loc[0]}\")\n",
        "print(f\"Number of instances with Glaucoma (1).....: {class_distribution.loc[1]}\")\n",
        "print(f\"Percentage without Glaucoma (0)...........: {class_percentage.loc[0]:.2f}%\")\n",
        "print(f\"Percentage with Glaucoma (1)..............: {class_percentage.loc[1]:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bkmohC3CF7Z8",
        "outputId": "d2de18f2-e72e-44ed-e710-5f9453824426"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Distribution:\n",
            "0    482\n",
            "1    168\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n",
            "Percentage of each class:\n",
            "0    74.153846\n",
            "1    25.846154\n",
            "Name: Glaucoma, dtype: float64\n",
            "\n",
            "Number of instances without Glaucoma (0)..: 482\n",
            "Number of instances with Glaucoma (1).....: 168\n",
            "Percentage without Glaucoma (0)...........: 74.15%\n",
            "Percentage with Glaucoma (1)..............: 25.85%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Oversampling the dataset"
      ],
      "metadata": {
        "id": "sS__m6I_KTlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the balance of the dataset\n",
        "class_distribution = glaucoma_data['Glaucoma'].value_counts()\n",
        "print(f\"Class Distribution before balancing:\\n{class_distribution}\\n\")\n",
        "\n",
        "# [Code to preprocess image remains unchanged]\n",
        "\n",
        "# [Assuming you choose to balance by oversampling the minority class]\n",
        "\n",
        "# Separate the dataset into two based on the class\n",
        "class_0 = glaucoma_data[glaucoma_data['Glaucoma'] == 0]\n",
        "class_1 = glaucoma_data[glaucoma_data['Glaucoma'] == 1]\n",
        "\n",
        "# Oversample the minority class. For example, if class_1 is the minority:\n",
        "oversampled_class_1 = class_1.sample(len(class_0), replace=True)\n",
        "\n",
        "# Combine the oversampled class with the other class\n",
        "balanced_glaucoma_data = pd.concat([class_0, oversampled_class_1])\n",
        "\n",
        "# Shuffle the dataset to mix the oversampled data\n",
        "balanced_glaucoma_data = balanced_glaucoma_data.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "# Check the new balance of the dataset\n",
        "new_class_distribution = balanced_glaucoma_data['Glaucoma'].value_counts()\n",
        "print(f\"Class Distribution after balancing:\\n{new_class_distribution}\\n\")\n",
        "\n",
        "# [Rest of your code to preprocess, split, and train the model]\n",
        "\n",
        "# Note: When using oversampling, make sure to split the dataset into train, validation,\n",
        "# and test sets after balancing to ensure that the test set reflects the original class distribution.\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pr1-YMlyKNGQ",
        "outputId": "08d69942-e02a-481f-d7d8-81e0152f4c73"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution before balancing:\n",
            "0    482\n",
            "1    168\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n",
            "Class Distribution after balancing:\n",
            "1    482\n",
            "0    482\n",
            "Name: Glaucoma, dtype: int64\n",
            "\n"
          ]
        }
      ]
    }
  ]
}